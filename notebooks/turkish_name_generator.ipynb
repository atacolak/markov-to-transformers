{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "GbLzfsHKE9ja"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "g = torch.Generator().manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "  def __init__(self, ins, outs, bias=False):\n",
        "    self.weights = torch.empty(outs, ins)\n",
        "    torch.nn.init.kaiming_uniform_(self.weights, mode='fan_in', nonlinearity='relu', generator=g)\n",
        "    if bias:\n",
        "      self.biases = torch.rand(outs, generator=g)\n",
        "    else:\n",
        "      self.biases = None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    pre_act = x @ self.weights.T\n",
        "    if self.biases is not None:\n",
        "      pre_act += self.biases\n",
        "    return pre_act\n",
        "\n",
        "  def params(self):\n",
        "    return [self.weights] + [self.biases] if self.biases is not None else [self.weights]"
      ],
      "metadata": {
        "id": "F1eFZB7cFF4n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "  def __call__(self, x):\n",
        "    self.out = F.relu(x)\n",
        "    return self.out"
      ],
      "metadata": {
        "id": "EvkrR0BmLuQm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNorm1d:\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.dim = dim\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # gamma & beta: trainable parameters to scale or move the normed batch\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # for inference\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    if self.training:   # train vars\n",
        "      xmean = x.mean(0, keepdim=True)\n",
        "      xvar = x.var(0, keepdim=True)\n",
        "    else:               # inference vars\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "\n",
        "    if self.training: # calculate running mean/var\n",
        "      self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "      self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def params(self):\n",
        "    return [self.gamma] + [self.beta]"
      ],
      "metadata": {
        "id": "sHru16RSL4u1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "PgTmKI5EW0Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 100 #neuron count for hidden layers\n",
        "\n",
        "\n",
        "layers = [\n",
        "    Linear(26)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj74xXmtiuOG",
        "outputId": "e36fb047-c007-4c2a-b113-a7b16b9b41e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1927, -0.2194,  0.2408, -0.6802, -1.2519, -0.7259,  0.0289, -0.4021],\n",
              "        [-0.0124, -0.8474,  0.5563,  0.5899,  0.7548,  0.2843, -0.2643,  1.1209],\n",
              "        [ 0.3482, -1.3332, -0.9160,  0.2289,  1.0687,  0.5881,  1.0930,  1.3121]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('turkish_names.txt', 'r') as f:\n",
        "  lines = f.read().splitlines()\n",
        "len(lines)\n",
        "\n",
        "trchr_to_utf8 = {\n",
        "    'İ': 'i',\n",
        "    'I': '!',\n",
        "    'Ö': '@',\n",
        "    'Ü': '#',\n",
        "    'Ş': '$',\n",
        "    'Ç': '^',\n",
        "    'Ğ': '&'}\n",
        "\n",
        "words = [word for line in lines for word in line.split()]\n",
        "names = [''.join(trchr_to_utf8.get(ch, ch) for ch in name).lower() for name in words]\n",
        "# ^ turkish phonemes transmogrified into utf-8 sigils ^-^\n",
        "names[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV21dz9mmszn",
        "outputId": "3a387fd8-6ef9-421a-ed85-dbf8011828fe"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jale',\n",
              " 'ali',\n",
              " 'mahmut',\n",
              " 'mansur',\n",
              " 'k#r$ad',\n",
              " 'gamze',\n",
              " 'mira^',\n",
              " 'y#cel',\n",
              " 'kubilay',\n",
              " 'hayati']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = ['.'] + sorted(list(set(ch for name in names for ch in name)))\n",
        "# ^ no need to sort tbh.    '.' as special start/end token.\n",
        "i_to_s = {i: chars[i] for i in range(len(chars))}\n",
        "s_to_i = {v: k for k, v in i_to_s.items()}"
      ],
      "metadata": {
        "id": "m9laLxgZmuoG"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3 # how many characters should it take to predict the next one?\n",
        "# . . . -> a; . . a -> t; . a t -> a\n",
        "def create_dataset(names):\n",
        "  X, Y = [], []\n",
        "  for name in names:\n",
        "    name = f\"{name}.\"   # add end token to each name\n",
        "    context = [0] * block_size # initialized as `. . .`\n",
        "    for ch in name:\n",
        "      X.append(context)\n",
        "      Y.append(s_to_i[ch])\n",
        "      context = context[1:] + [s_to_i[ch]]\n",
        "  return torch.tensor(X), torch.tensor(Y)"
      ],
      "metadata": {
        "id": "PuqA7JObulfn"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(names)\n",
        "\n",
        "n1 = int(len(names) * 0.1)\n",
        "\n",
        "Xtr, Ytr = create_dataset(names[n1*2:]) # 80% train split\n",
        "Xte, Yte = create_dataset(names[:n1]) # 10% test\n",
        "Xval, Yval = create_dataset(names[n1:n1*2]) # 10% valid\n",
        "\n",
        "# precision spell\n",
        "avg_len = sum(len(name) + 1 for name in names) / len(names)\n",
        "actual = (len(Xtr) + len(Xte) + len(Xval)) / len(names)\n",
        "assert abs(avg_len - actual) < 1e-6, '\\nSize mismatch.\\nWhat did you break?'"
      ],
      "metadata": {
        "id": "cACbF1JGxXy3"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steps for tomorrow:\n",
        "# create an embedding table. we should be able to plug in our indices corresponding to characters,\n",
        "# and get an embedding of them.\n",
        "\n",
        "# we will backpropagate through the embeddings."
      ],
      "metadata": {
        "id": "HUL3A4o41BWH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}